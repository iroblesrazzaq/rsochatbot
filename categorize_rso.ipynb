{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to add better categories to RSO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from groq import Groq\n",
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import tiktoken\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # This loads the variables from .env\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    ")\n",
    "token_bucket = TokenBucket(tokens_per_minute=4500)  # Using 4500 to be conservative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenBucket:\n",
    "    def __init__(self, tokens_per_minute: int = 5000):\n",
    "        self.max_tokens = tokens_per_minute\n",
    "        self.tokens = tokens_per_minute\n",
    "        self.last_update = datetime.now()\n",
    "        self.tokens_per_minute = tokens_per_minute\n",
    "\n",
    "    def update_tokens(self):\n",
    "        now = datetime.now()\n",
    "        time_passed = now - self.last_update\n",
    "        self.tokens = min(\n",
    "            self.max_tokens,\n",
    "            self.tokens + (time_passed.total_seconds() * self.tokens_per_minute / 60)\n",
    "        )\n",
    "        self.last_update = now\n",
    "\n",
    "    def consume(self, tokens: int) -> float:\n",
    "        self.update_tokens()\n",
    "        if self.tokens < tokens:\n",
    "            wait_time = (tokens - self.tokens) * 60 / self.tokens_per_minute\n",
    "            return wait_time\n",
    "        self.tokens -= tokens\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Estimate token count using tiktoken\"\"\"\n",
    "    # Using cl100k_base as an approximation\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def exponential_backoff(attempt: int, base_delay: float = 1) -> float:\n",
    "    \"\"\"Calculate delay with jitter for exponential backoff\"\"\"\n",
    "    delay = min(300, base_delay * (2 ** attempt))  # Cap at 5 minutes\n",
    "    jitter = random.uniform(0, 0.1 * delay)\n",
    "    return delay + jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_CATEGORIES = [\n",
    "    \"Biology\", \"Business\", \"Chemistry\", \"Physics\", \"Mathematics\", \"Computer Science\", \n",
    "    \"Data Science\", \"Economics\", \"Psychology\", \"Sociology\", \"Political Science\",\n",
    "    \"History\", \"Philosophy\", \"Literature\", \"Languages\", \"Law\", \"Medicine\",\n",
    "    \"Nursing\", \"Public Health\", \"Engineering\", \"Environmental Science\",\n",
    "    \"Finance\", \"Investment\", \"Quantitative Trading\", \"Private Equity\",\n",
    "    \"Venture Capital\", \"Consulting\", \"Marketing\", \"Entrepreneurship\",\n",
    "    \"Real Estate\", \"Technology\", \"Software Development\", \"Product Management\",\n",
    "    \"Healthcare\", \"Legal\", \"Research\", \"Journalism\", \"Media Production\",\n",
    "    \"Visual Arts\", \"Painting\", \"Photography\", \"Digital Art\", \"Music\",\n",
    "    \"Band\", \"Choir\", \"A Cappella\", \"Theater\", \"Dance\", \"Film\",\n",
    "    \"Creative Writing\", \"Design\", \"Cultural\", \"International\", \"Religious\",\n",
    "    \"LGBTQ+\", \"Gender & Sexuality\", \"Social Justice\", \"Political\", \"Activism\",\n",
    "    \"Community Service/volunteering\", \"Mentorship\", \"Environmental\", \"Sports\"\n",
    "    \"Team Sports\", \"Individual Sports\", \"Gaming\",\n",
    "    \"Debate\", \"Model UN\", \"Food & Cooking\", \"Travel\", \"Outdoor Activities\",\n",
    "    \"Student Government\", \"Publications\", \"Journalism\", \"Mental Health\", \"Wellness\",\n",
    "    \"Career Development\", \"Academic Support\", \"Leadership\", \"Greek Life\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_EXAMPLES = [\n",
    "    {\n",
    "        \"name\": \"Investment Banking Group\",\n",
    "        \"description\": \"A professional organization dedicated to educating members about investment banking, private equity, and financial markets. We host networking events, technical workshops, and mock interviews to prepare students for careers in finance.\",\n",
    "        \"ideal_categories\": [\"Finance\", \"Investment\", \"Career Development\"],\n",
    "        \"explanation\": \"This RSO focuses on finance education and career preparation, warranting multiple related financial categories.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Data Science for Social Good\",\n",
    "        \"description\": \"We apply data science and machine learning techniques to tackle social issues in healthcare, education, and environmental sustainability. Members work on real-world projects while learning technical skills.\",\n",
    "        \"ideal_categories\": [\"Data Science\", \"Computer Science\", \"Community Service/volunteering\"],\n",
    "        \"explanation\": \"Combines technical data science work with social impact, deserving both technical and service categories.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Mental Health Alliance\",\n",
    "        \"description\": \"A student organization focused on promoting mental health awareness, reducing stigma, and connecting students with resources. We organize wellness workshops, peer support groups, and educational events.\",\n",
    "        \"ideal_categories\": [\"Mental Health\", \"Wellness\", \"Student Life\"],\n",
    "        \"explanation\": \"Focuses on mental health and wellness within student life context.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(rso: Dict) -> str:\n",
    "    \"\"\"Create a prompt for the LLM to categorize an RSO.\"\"\"\n",
    "    few_shot_text = \"\\n---\\n\".join([\n",
    "        f\"\"\"\n",
    "Name: {ex['name']}\n",
    "Description: {ex['description']}\n",
    "Categories: {', '.join(ex['ideal_categories'])}\n",
    "Explanation: {ex['explanation']}\"\"\" \n",
    "        for ex in FEW_SHOT_EXAMPLES\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"You are an expert at categorizing university student organizations. Given an RSO's name and description, assign it relevant categories from the provided list. Each RSO can have multiple categories if appropriate.\n",
    "\n",
    "Valid categories: {', '.join(VALID_CATEGORIES)}\n",
    "\n",
    "Here are some examples:\n",
    "{few_shot_text}\n",
    "\n",
    "For the following RSO, please provide:\n",
    "1. A list of relevant categories (can be multiple)\n",
    "2. A confidence score (0-100) for each category\n",
    "3. A brief explanation of your categorization\n",
    "\n",
    "Name: {rso['name']}\n",
    "Description: {rso.get('full_description', '') or rso.get('description_preview', '')}\n",
    "\n",
    "Response should be in JSON format:\n",
    "{{\n",
    "  \"categories\": [\n",
    "    {{\"name\": \"category_name\", \"confidence\": 95}},\n",
    "    {{\"name\": \"another_category\", \"confidence\": 85}}\n",
    "  ],\n",
    "  \"explanation\": \"Brief explanation of categorization\"\n",
    "}}\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_rso(rso: Dict, attempt: int = 0) -> Optional[Dict]:\n",
    "    \"\"\"Categorize a single RSO using the Groq API with rate limiting.\"\"\"\n",
    "    try:\n",
    "        prompt = create_prompt(rso)\n",
    "        estimated_tokens = count_tokens(prompt) + 500  # Add buffer for response\n",
    "        \n",
    "        # Check token bucket\n",
    "        wait_time = token_bucket.consume(estimated_tokens)\n",
    "        if wait_time > 0:\n",
    "            print(f\"\\nRate limit approaching, waiting {wait_time:.2f} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            temperature=0.3,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        response = json.loads(completion.choices[0].message.content)\n",
    "        \n",
    "        # Validate categories against our list\n",
    "        response['categories'] = [\n",
    "            cat for cat in response['categories'] \n",
    "            if cat['name'] in VALID_CATEGORIES\n",
    "        ]\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        if \"rate_limit\" in str(e).lower():\n",
    "            if attempt < 5:  # Max 5 retries\n",
    "                delay = exponential_backoff(attempt)\n",
    "                print(f\"\\nRate limit hit for {rso['name']}, waiting {delay:.2f} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                return categorize_rso(rso, attempt + 1)\n",
    "            else:\n",
    "                print(f\"\\nMax retries reached for {rso['name']}\")\n",
    "        print(f\"Error categorizing RSO {rso['name']}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rsos(input_file: str = None, output_file: str = None, rsos: List[Dict] = None):\n",
    "    \"\"\"Process all RSOs from input file or list and save results to output file.\"\"\"\n",
    "    try:\n",
    "        # Read input JSON if file provided, otherwise use provided list\n",
    "        if input_file:\n",
    "            with open(input_file, 'r') as f:\n",
    "                rsos = json.load(f)\n",
    "        \n",
    "        if not rsos:\n",
    "            raise ValueError(\"No RSOs provided\")\n",
    "            \n",
    "        results = []\n",
    "        batch_size = 3  # Reduced batch size\n",
    "        \n",
    "        # Process RSOs in batches with progress bar\n",
    "        for i in tqdm(range(0, len(rsos), batch_size)):\n",
    "            batch = rsos[i:i + batch_size]\n",
    "            batch_results = []\n",
    "            \n",
    "            # Process each RSO in batch\n",
    "            for rso in batch:\n",
    "                categorization = categorize_rso(rso)\n",
    "                if categorization:\n",
    "                    rso['ai_categories'] = categorization['categories']\n",
    "                    rso['categorization_explanation'] = categorization['explanation']\n",
    "                batch_results.append(rso)\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "            \n",
    "            # Save intermediate results every batch\n",
    "            if output_file:\n",
    "                with open(f\"{output_file}.partial\", 'w') as f:\n",
    "                    json.dump(results, f, indent=2)\n",
    "            \n",
    "            # Add delay between batches\n",
    "            time.sleep(2)  # Conservative delay between batches\n",
    "        \n",
    "        # Write final results to output file if provided\n",
    "        if output_file:\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "            print(f'\\nCategorization complete! Results saved to {output_file}')\n",
    "            \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'\\nError processing RSOs: {str(e)}')\n",
    "        # Save partial results if available\n",
    "        if results and output_file:\n",
    "            with open(f\"{output_file}.error_partial\", 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "            print(f'Partial results saved to {output_file}.error_partial')\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = process_rsos('rso_data_detailed.json', 'categorized_rsos.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
