{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlueprintScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://blueprint.uchicago.edu/organizations\"\n",
    "        self.category_map = {\n",
    "            '4150': 'Academic Interest',\n",
    "            '4174': 'Campus and Student Life',\n",
    "            '4151': 'Community Service',\n",
    "            '4152': 'Cultural & Ethnic',\n",
    "            '4153': 'Fine Arts',\n",
    "            '8195': 'Graduate/Professional',\n",
    "            '4155': 'Media & Publication',\n",
    "            '4156': 'Political & Advocacy',\n",
    "            '4157': 'Religious & Spiritual',\n",
    "            '4158': 'Social',\n",
    "            '4159': 'Sports Clubs',\n",
    "            '4288': 'Student Government',\n",
    "            '4289': 'University Department/Program'\n",
    "        }\n",
    "        self.driver = None\n",
    "        self.rso_data = []\n",
    "    \n",
    "    def setup_driver(self):\n",
    "        \"\"\"Initialize Selenium WebDriver with appropriate options\"\"\"\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')\n",
    "        options.add_argument('--disable-gpu')\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "        options.add_argument('--window-size=1920,1080')\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "    def load_all_rsos(self, expected_count=408):\n",
    "        \"\"\"Click 'Show More' button until all RSOs are loaded\n",
    "        \n",
    "        Args:\n",
    "            expected_count (int): Expected number of RSOs to load\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if expected number of RSOs were loaded, False otherwise\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting to load all RSOs (expecting {expected_count})...\")\n",
    "        page_source_length = 0\n",
    "        attempts = 0\n",
    "        max_attempts = 50  # Increased max attempts to ensure we get all RSOs\n",
    "        \n",
    "        while attempts < max_attempts:\n",
    "            # Check current number of RSOs\n",
    "            current_rsos = len(self.driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/organization/\"]'))\n",
    "            logger.info(f\"Currently loaded RSOs: {current_rsos}\")\n",
    "            \n",
    "            if current_rsos >= expected_count:\n",
    "                logger.info(f\"Successfully loaded all {current_rsos} RSOs\")\n",
    "                return True\n",
    "                \n",
    "            # Continue with show more clicks\n",
    "            try:\n",
    "                # Try to find and click the \"Show More\" button\n",
    "                show_more = WebDriverWait(self.driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \n",
    "                    \"//button[.//span[contains(text(), 'Load More')]]\"))\n",
    "                )\n",
    "                \n",
    "                # If the button is not visible in viewport, scroll to it\n",
    "                self.driver.execute_script(\"\"\"\n",
    "                    var element = arguments[0];\n",
    "                    var headerOffset = 100;\n",
    "                    var elementPosition = element.getBoundingClientRect().top;\n",
    "                    var offsetPosition = elementPosition + window.pageYOffset - headerOffset;\n",
    "                    window.scrollTo({\n",
    "                        top: offsetPosition,\n",
    "                        behavior: 'smooth'\n",
    "                    });\n",
    "                \"\"\", show_more)\n",
    "                time.sleep(0.5)  # Short pause for scroll\n",
    "                \n",
    "                # Click the button\n",
    "                self.driver.execute_script(\"arguments[0].click();\", show_more)\n",
    "                logger.info(f\"Clicked 'Load More' button, attempt {attempts + 1}\")\n",
    "                \n",
    "                # Wait for new content\n",
    "                time.sleep(2)  # Increased wait time for reliability\n",
    "                \n",
    "                # Check if page content has grown\n",
    "                new_length = len(self.driver.page_source)\n",
    "                if new_length == page_source_length:\n",
    "                    logger.info(\"No new content loaded, finishing...\")\n",
    "                    break\n",
    "                \n",
    "                page_source_length = new_length\n",
    "                attempts += 1\n",
    "                \n",
    "            except TimeoutException:\n",
    "                logger.info(\"No more 'Show More' button found, all content loaded\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error clicking 'Show More': {str(e)}\")\n",
    "                break\n",
    "                \n",
    "        # Final check after all attempts\n",
    "        final_count = len(self.driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/organization/\"]'))\n",
    "        logger.info(f\"Finished loading RSOs after {attempts} attempts. Final count: {final_count}\")\n",
    "        return final_count >= expected_count\n",
    "    \n",
    "    def extract_rso_info_from_card(self, card_element):\n",
    "        \"\"\"Extract RSO information from a card element\"\"\"\n",
    "        try:\n",
    "            # Get the link and RSO name from the href\n",
    "            link = card_element.get('href')\n",
    "            rso_name = link.split('/')[-1] if link else None\n",
    "            \n",
    "            # Get the display name (from img alt or other source)\n",
    "            img = card_element.find('img')\n",
    "            display_name = img.get('alt') if img else None\n",
    "            \n",
    "            # Get the description excerpt\n",
    "            description = card_element.find('p', class_='DescriptionExcerpt')\n",
    "            description_text = description.text.strip() if description else \"\"\n",
    "            \n",
    "            # Get the image URL\n",
    "            img_src = img.get('src') if img else None\n",
    "            \n",
    "            return {\n",
    "                'name': display_name,\n",
    "                'url_name': rso_name,\n",
    "                'full_url': urljoin(\"https://blueprint.uchicago.edu\", link) if link else None,\n",
    "                'description_preview': description_text,\n",
    "                'image_url': img_src\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting RSO card info: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_rso_cards(self):\n",
    "        \"\"\"Extract all RSO cards from the loaded page\"\"\"\n",
    "        logger.info(\"Starting to extract RSO cards...\")\n",
    "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        \n",
    "        # Find all RSO card links\n",
    "        rso_cards = soup.find_all('a', href=lambda x: x and x.startswith('/organization/'))\n",
    "        \n",
    "        rso_info = []\n",
    "        for card in rso_cards:\n",
    "            info = self.extract_rso_info_from_card(card)\n",
    "            if info:\n",
    "                rso_info.append(info)\n",
    "        \n",
    "        logger.info(f\"Found {len(rso_info)} RSO cards\")\n",
    "        return rso_info\n",
    "    \n",
    "    def scrape_all_rsos(self):\n",
    "        \"\"\"Main function to scrape all RSOs\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Starting RSO scraping process...\")\n",
    "            self.setup_driver()\n",
    "            \n",
    "            # First pass: Get all RSOs and their basic info\n",
    "            logger.info(\"Loading main page...\")\n",
    "            self.driver.get(self.base_url)\n",
    "            self.load_all_rsos()\n",
    "            rso_info = self.extract_rso_cards()\n",
    "            \n",
    "            if not rso_info:\n",
    "                logger.error(\"No RSO cards found!\")\n",
    "                return []\n",
    "            \n",
    "            if len(rso_info) < 408:\n",
    "                logger.error(f\"Only found {len(rso_info)} RSOs, expected 408. Retrying...\")\n",
    "                # Try one more time with longer waits\n",
    "                self.driver.get(self.base_url)\n",
    "                time.sleep(3)  # Longer initial wait\n",
    "                success = self.load_all_rsos(408)\n",
    "                if not success:\n",
    "                    logger.error(\"Failed to load all RSOs even after retry\")\n",
    "                rso_info = self.extract_rso_cards()\n",
    "                \n",
    "            if len(rso_info) < 408:\n",
    "                logger.error(f\"Warning: Only found {len(rso_info)} RSOs out of 408 expected\")\n",
    "            \n",
    "            # Save data to JSON file\n",
    "            with open('rso_data.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(rso_info, f, indent=2, ensure_ascii=False)\n",
    "                \n",
    "            logger.info(f\"Successfully scraped {len(rso_info)} RSOs\")\n",
    "            return rso_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in scraping process: {str(e)}\")\n",
    "            return []\n",
    "        finally:\n",
    "            if self.driver:\n",
    "                self.driver.quit()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = BlueprintScraper()\n",
    "scraper.scrape_all_rsos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def remove_field_from_json(file_path, field_to_remove):\n",
    "    # Read the JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # If the data is a dictionary, remove the field\n",
    "    if isinstance(data, dict):\n",
    "        if field_to_remove in data:\n",
    "            del data[field_to_remove]\n",
    "    # If the data is a list of dictionaries, remove the field from each item\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, dict) and field_to_remove in item:\n",
    "                del item[field_to_remove]\n",
    "    \n",
    "    # Write the updated data back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "# Example usage\n",
    "file_path = 'rso_data.json'\n",
    "field_to_remove = 'image_url'\n",
    "\n",
    "try:\n",
    "    remove_field_from_json(file_path, field_to_remove)\n",
    "    print(f\"Successfully removed '{field_to_remove}' from {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CategoryCollector:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://blueprint.uchicago.edu/organizations\"\n",
    "        self.category_map = {\n",
    "            '4150': 'Academic Interest',\n",
    "            '4174': 'Campus and Student Life',\n",
    "            '4151': 'Community Service',\n",
    "            '4152': 'Cultural & Ethnic',\n",
    "            '4153': 'Fine Arts',\n",
    "            '8195': 'Graduate/Professional',\n",
    "            '4155': 'Media & Publication',\n",
    "            '4156': 'Political & Advocacy',\n",
    "            '4157': 'Religious & Spiritual',\n",
    "            '4158': 'Social',\n",
    "            '4159': 'Sports Clubs',\n",
    "            '4288': 'Student Government',\n",
    "            '4289': 'University Department/Program'\n",
    "        }\n",
    "        self.driver = None\n",
    "        self.rso_categories = defaultdict(set)\n",
    "    \n",
    "    def setup_driver(self):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')\n",
    "        options.add_argument('--disable-gpu')\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "        options.add_argument('--window-size=1920,1080')\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    def load_all_rsos(self, category_name=\"\"):\n",
    "        logger.info(f\"Loading RSOs for {category_name}...\")\n",
    "        attempts = 0\n",
    "        max_attempts = 50\n",
    "        \n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                show_more = WebDriverWait(self.driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \n",
    "                    \"//button[.//span[contains(text(), 'Load More')]]\"))\n",
    "                )\n",
    "                \n",
    "                self.driver.execute_script(\"\"\"\n",
    "                    var element = arguments[0];\n",
    "                    var headerOffset = 100;\n",
    "                    var elementPosition = element.getBoundingClientRect().top;\n",
    "                    var offsetPosition = elementPosition + window.pageYOffset - headerOffset;\n",
    "                    window.scrollTo({\n",
    "                        top: offsetPosition,\n",
    "                        behavior: 'smooth'\n",
    "                    });\n",
    "                \"\"\", show_more)\n",
    "                \n",
    "                time.sleep(0.5)\n",
    "                self.driver.execute_script(\"arguments[0].click();\", show_more)\n",
    "                time.sleep(2)\n",
    "                attempts += 1\n",
    "                \n",
    "            except TimeoutException:\n",
    "                break\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in load_all_rsos for {category_name}: {str(e)}\")\n",
    "                break\n",
    "    \n",
    "    def collect_categories(self):\n",
    "        try:\n",
    "            self.setup_driver()\n",
    "            \n",
    "            # Load existing RSO data\n",
    "            with open('rso_data.json', 'r', encoding='utf-8') as f:\n",
    "                rso_data = json.load(f)\n",
    "            \n",
    "            # Create lookup of url_names\n",
    "            all_rsos = {rso['url_name'] for rso in rso_data if rso.get('url_name')}\n",
    "            logger.info(f\"Loaded {len(all_rsos)} RSOs from existing data\")\n",
    "            \n",
    "            # Check each category\n",
    "            for cat_id, cat_name in self.category_map.items():\n",
    "                try:\n",
    "                    logger.info(f\"Checking category: {cat_name}\")\n",
    "                    self.driver.get(f\"{self.base_url}?categories={cat_id}\")\n",
    "                    self.load_all_rsos(cat_name)\n",
    "                    \n",
    "                    soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "                    category_links = soup.find_all('a', href=lambda x: x and x.startswith('/organization/'))\n",
    "                    category_rsos = {link['href'].split('/')[-1] for link in category_links}\n",
    "                    \n",
    "                    # Add category to each RSO found\n",
    "                    for rso in category_rsos:\n",
    "                        self.rso_categories[rso].add(cat_name)\n",
    "                    \n",
    "                    logger.info(f\"Found {len(category_rsos)} RSOs in {cat_name}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing category {cat_name}: {str(e)}\")\n",
    "            \n",
    "            # Update the existing data with categories\n",
    "            for rso in rso_data:\n",
    "                url_name = rso.get('url_name')\n",
    "                if url_name:\n",
    "                    rso['categories'] = list(self.rso_categories.get(url_name, set()))\n",
    "            \n",
    "            # Save updated data\n",
    "            with open('rso_data_with_categories.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(rso_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            # Log category statistics\n",
    "            logger.info(\"\\nCategory Statistics:\")\n",
    "            for cat_name in self.category_map.values():\n",
    "                count = sum(1 for cats in self.rso_categories.values() if cat_name in cats)\n",
    "                logger.info(f\"  {cat_name}: {count} RSOs\")\n",
    "            \n",
    "            no_category_count = sum(1 for rso in all_rsos if not self.rso_categories.get(rso))\n",
    "            logger.info(f\"RSOs with no category: {no_category_count}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in category collection: {str(e)}\")\n",
    "        finally:\n",
    "            if self.driver:\n",
    "                self.driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collector = CategoryCollector()\n",
    "collector.collect_categories()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
