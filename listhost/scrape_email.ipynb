{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to scrape emails from given gmail and put into sql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.discovery import build\n",
    "import base64\n",
    "import os.path\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import email\n",
    "from email.utils import parsedate_to_datetime\n",
    "from typing import List, Dict, Optional\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RSOEmailProcessor:\n",
    "    def __init__(self, db_path: str = 'rso_emails.db'):\n",
    "        self.db_path = db_path\n",
    "        self.SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "        self.setup_logging()\n",
    "        \n",
    "    def setup_logging(self):\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler('rso_email_processor.log'),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def init_database(self):\n",
    "        \"\"\"Initialize SQLite database with necessary tables\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                \n",
    "                # Create RSO emails table\n",
    "                cursor.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS rso_emails (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    rso_listhost TEXT NOT NULL,\n",
    "                    subject TEXT,\n",
    "                    sender TEXT,\n",
    "                    email_date TIMESTAMP,\n",
    "                    content TEXT,\n",
    "                    message_id TEXT UNIQUE,\n",
    "                    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "                ''')\n",
    "                \n",
    "                # Create RSOs table\n",
    "                cursor.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS rsos (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    name TEXT NOT NULL,\n",
    "                    listhost TEXT UNIQUE,\n",
    "                    last_email_check TIMESTAMP\n",
    "                )\n",
    "                ''')\n",
    "                \n",
    "                conn.commit()\n",
    "                self.logger.info(\"Database initialized successfully\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error initializing database: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_gmail_service(self):\n",
    "        \"\"\"Initialize Gmail API service\"\"\"\n",
    "        creds = None\n",
    "        if os.path.exists('token.pickle'):\n",
    "            with open('token.pickle', 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "        \n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    'credentials.json', self.SCOPES)\n",
    "                creds = flow.run_local_server(port=8080)\n",
    "            \n",
    "            with open('token.pickle', 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "\n",
    "        return build('gmail', 'v1', credentials=creds)\n",
    "\n",
    "    def extract_email_content(self, message) -> Dict:\n",
    "        \"\"\"Extract relevant content from email message\"\"\"\n",
    "        try:\n",
    "            headers = message['payload']['headers']\n",
    "            subject = next((h['value'] for h in headers if h['name'] == 'Subject'), '')\n",
    "            sender = next((h['value'] for h in headers if h['name'] == 'From'), '')\n",
    "            message_id = next((h['value'] for h in headers if h['name'] == 'Message-ID'), '')\n",
    "            date_str = next((h['value'] for h in headers if h['name'] == 'Date'), '')\n",
    "            \n",
    "            # Parse email date\n",
    "            try:\n",
    "                email_date = parsedate_to_datetime(date_str)\n",
    "            except:\n",
    "                email_date = datetime.now()\n",
    "\n",
    "            # Get email body\n",
    "            if 'parts' in message['payload']:\n",
    "                parts = message['payload']['parts']\n",
    "                body = ''\n",
    "                for part in parts:\n",
    "                    if part['mimeType'] == 'text/plain':\n",
    "                        if 'data' in part['body']:\n",
    "                            body += base64.urlsafe_b64decode(\n",
    "                                part['body']['data']).decode()\n",
    "            else:\n",
    "                body = base64.urlsafe_b64decode(\n",
    "                    message['payload']['body']['data']).decode()\n",
    "\n",
    "            return {\n",
    "                'subject': subject,\n",
    "                'sender': sender,\n",
    "                'content': body,\n",
    "                'email_date': email_date,\n",
    "                'message_id': message_id\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error extracting email content: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def load_rso_data(self, json_path: str):\n",
    "        \"\"\"Load RSO data from JSON file into SQLite database\"\"\"\n",
    "        try:\n",
    "            with open(json_path, 'r') as f:\n",
    "                rsos = json.load(f)\n",
    "\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                for rso in rsos:\n",
    "                    listhost = rso.get('additional_info', {}).get('RSO Listhost')\n",
    "                    if listhost:\n",
    "                        cursor.execute('''\n",
    "                        INSERT OR REPLACE INTO rsos (name, listhost)\n",
    "                        VALUES (?, ?)\n",
    "                        ''', (rso['name'], listhost))\n",
    "                conn.commit()\n",
    "                \n",
    "            self.logger.info(f\"Loaded RSO data from {json_path}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading RSO data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def process_new_emails(self, query: str = None):\n",
    "        \"\"\"Process new emails from Gmail and store in database\"\"\"\n",
    "        try:\n",
    "            service = self.get_gmail_service()\n",
    "            \n",
    "            # Get list of all RSO listhosts\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                cursor.execute('SELECT listhost FROM rsos')\n",
    "                listhosts = {row[0] for row in cursor.fetchall()}\n",
    "\n",
    "            # Query Gmail API\n",
    "            query = query or 'newer_than:1d'  # Default to last day if no query provided\n",
    "            results = service.users().messages().list(\n",
    "                userId='me', q=query).execute()\n",
    "            messages = results.get('messages', [])\n",
    "\n",
    "            processed_count = 0\n",
    "            for message in messages:\n",
    "                msg = service.users().messages().get(\n",
    "                    userId='me', id=message['id']).execute()\n",
    "                \n",
    "                email_data = self.extract_email_content(msg)\n",
    "                if not email_data:\n",
    "                    continue\n",
    "\n",
    "                # Check if email is from a known listhost\n",
    "                sender_domain = email_data['sender'].split('@')[-1]\n",
    "                if sender_domain != 'lists.uchicago.edu':\n",
    "                    continue\n",
    "\n",
    "                sender_listhost = email_data['sender'].split('@')[0]\n",
    "                if sender_listhost not in listhosts:\n",
    "                    continue\n",
    "\n",
    "                # Store in database\n",
    "                with sqlite3.connect(self.db_path) as conn:\n",
    "                    cursor = conn.cursor()\n",
    "                    cursor.execute('''\n",
    "                    INSERT OR IGNORE INTO rso_emails \n",
    "                    (rso_listhost, subject, sender, email_date, content, message_id)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?)\n",
    "                    ''', (\n",
    "                        sender_listhost,\n",
    "                        email_data['subject'],\n",
    "                        email_data['sender'],\n",
    "                        email_data['email_date'],\n",
    "                        email_data['content'],\n",
    "                        email_data['message_id']\n",
    "                    ))\n",
    "                    \n",
    "                    # Update last_email_check for the RSO\n",
    "                    cursor.execute('''\n",
    "                    UPDATE rsos \n",
    "                    SET last_email_check = CURRENT_TIMESTAMP\n",
    "                    WHERE listhost = ?\n",
    "                    ''', (sender_listhost,))\n",
    "                    \n",
    "                    conn.commit()\n",
    "                    processed_count += 1\n",
    "\n",
    "            self.logger.info(f\"Processed {processed_count} new emails\")\n",
    "            return processed_count\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing emails: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_rso_emails(self, rso_listhost: str, limit: int = 100) -> List[Dict]:\n",
    "        \"\"\"Retrieve emails for a specific RSO\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                cursor.execute('''\n",
    "                SELECT subject, sender, email_date, content\n",
    "                FROM rso_emails\n",
    "                WHERE rso_listhost = ?\n",
    "                ORDER BY email_date DESC\n",
    "                LIMIT ?\n",
    "                ''', (rso_listhost, limit))\n",
    "                \n",
    "                emails = [{\n",
    "                    'subject': row[0],\n",
    "                    'sender': row[1],\n",
    "                    'date': row[2],\n",
    "                    'content': row[3]\n",
    "                } for row in cursor.fetchall()]\n",
    "                \n",
    "                return emails\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error retrieving RSO emails: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def get_email_statistics(self) -> Dict:\n",
    "        \"\"\"Get statistics about stored emails\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                \n",
    "                # Get total email count\n",
    "                cursor.execute('SELECT COUNT(*) FROM rso_emails')\n",
    "                total_emails = cursor.fetchone()[0]\n",
    "                \n",
    "                # Get email count per RSO\n",
    "                cursor.execute('''\n",
    "                SELECT r.name, COUNT(e.id) as email_count\n",
    "                FROM rsos r\n",
    "                LEFT JOIN rso_emails e ON r.listhost = e.rso_listhost\n",
    "                GROUP BY r.name\n",
    "                ORDER BY email_count DESC\n",
    "                ''')\n",
    "                rso_counts = dict(cursor.fetchall())\n",
    "                \n",
    "                # Get date range\n",
    "                cursor.execute('''\n",
    "                SELECT \n",
    "                    MIN(email_date) as earliest,\n",
    "                    MAX(email_date) as latest\n",
    "                FROM rso_emails\n",
    "                ''')\n",
    "                date_range = cursor.fetchone()\n",
    "                \n",
    "                return {\n",
    "                    'total_emails': total_emails,\n",
    "                    'rso_counts': rso_counts,\n",
    "                    'date_range': {\n",
    "                        'earliest': date_range[0],\n",
    "                        'latest': date_range[1]\n",
    "                    }\n",
    "                }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error getting email statistics: {str(e)}\")\n",
    "            return {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
